%%% Title:    TCSM: Multiple Group Models
%%% Author:   Kyle M. Lang
%%% Created:  ? (Adapted from Rebecca's Summer School slides)
%%% Modified: 2023-08-23

\documentclass[10pt]{beamer}
\usetheme{Utrecht}

\usepackage{graphicx}
\usepackage[natbibapa]{apacite}
\usepackage[libertine]{newtxmath}
\usepackage{fancybox}
\usepackage{booktabs}
\usepackage{relsize}
\usepackage{xcolor}
\usepackage{mathtools}
\usepackage{amsmath}

\graphicspath{{../figures/}}
\usepackage{tikz} 
\usetikzlibrary{arrows,calc,patterns,positioning,shapes,decorations.markings} 
\usetikzlibrary{decorations.pathmorphing} 

\newcommand{\eqit}[1]{\textrm{\textit{#1}}}
\newcommand{\pkg}[1]{\textbf{#1}}
\newcommand{\src}[1]{\texttt{#1}}
\newcommand{\rmsc}[1]{\textrm{\textsc{#1}}}

\title{Multiple Group Models \& Measurement Invariance}
\subtitle{Theory Construction and Statistical Modeling}
\author{Kyle M. Lang}
\institute{Department of Methodology \& Statistics\\Utrecht University}
\date{}

\begin{document}

<<setup, include = FALSE, cache = FALSE>>=
set.seed(235711)

dataDir <- "../data/"

library(knitr)
library(ggplot2)
library(MASS)
library(DAAG)
library(xtable)
library(MLmetrics)
library(dplyr)
library(mvtnorm)
library(lavaan)
library(tidySEM)
library(psych)
library(Hmisc)
library(lavaanPlot)

source("../../../code/supportFunctions.R")

options(width = 80)
opts_chunk$set(size = "footnotesize",
               fig.align = "center",
               fig.path = "figure/multiple_group-",
               message = FALSE,
               comment = "")
knit_theme$set('edit-kwrite')
@

%------------------------------------------------------------------------------%

\begin{frame}[t,plain]
  \titlepage
\end{frame}

%------------------------------------------------------------------------------%

\begin{frame}{Outline}
  \tableofcontents
\end{frame}

%------------------------------------------------------------------------------%

\section{Multiple Group}

%------------------------------------------------------------------------------%

\begin{frame}{From one group to multiple groups}
  \begin{itemize}
    \item EFA or CFA for single group:\\
      \includegraphics[height=3cm,keepaspectratio]{../figures/EFAandCFA.png} 
    \item EFA or CFA for multiple groups:\\
      \includegraphics[height=3cm,keepaspectratio]{../figures/MultipleGroup.png} 
  \end{itemize}
\end{frame}

%------------------------------------------------------------------------------%

\begin{frame}{General setup of multigroup analysis}
  \begin{enumerate}
    \item Each group treated as \textbf{separate dataset}.
      \begin{itemize}
        \item  Like ``select data'' in SPSS: select people who meet a specific condition (e.g., female, Dutch, etc)
        \item lavaan does it behind the scenes, after denoting your groups.
      \end{itemize}
    \item Model is fitted in each group separately.
    \item Apply constraints to test whether parameters are the same / significantly different across different groups.
  \end{enumerate}
\end{frame}

%------------------------------------------------------------------------------%

\section{MG regression in R}

%------------------------------------------------------------------------------%

\begin{frame}{Example: Multigroup regression}

  Regression example from lab meeting `Intro and regression':
  \begin{itemize}
    \item{Outcome: sw}
    \item{Predictors: overt and covert}
    \item{Group: gender (males and females)}
  \end{itemize}

\end{frame}

%------------------------------------------------------------------------------%

\begin{frame}[fragile]{Multigroup regression - lavaan model}

<<>>=
library(dplyr)
library(lavaan)

## Read in the data:
dat1 <- read.table("../data/popular_regr.txt",
                   header = TRUE, 
                   na.strings = c("-99", "-999")
) %>%
mutate(sex = factor(gender, labels = c("male", "female"))) %>%
filter(!is.na(sex))

## Define the model syntax:
mod1 <- 'sw ~ 1 + overt + covert'

## Fit the model:
fit1 <- sem(mod1, data = dat1, group = "sex")
@ 

\end{frame}

%------------------------------------------------------------------------------%

\begin{frame}[fragile]{Multigroup regression - lavaan model}

<<>>=
## Define the model syntax with parameter labels:
mod1 <- '
sw ~ c("b0m", "b0f") * 1 + 
     c("b1m", "b1f") * overt + 
     c("b2m", "b2f") * covert
'

## Fit the model:
fit1 <- sem(mod1, data = dat1, group = "sex")
@ 

\end{frame}

%------------------------------------------------------------------------------%

\begin{frame}[fragile, allowframebreaks]{Multigroup regression - lavaan output}

<<>>=
partSummary(fit1, 1:4)
@

\newpage

<<>>=
partSummary(fit1, 8:11)
@

\newpage

<<>>=
partSummary(fit1, 13:16)
@

\end{frame}

%------------------------------------------------------------------------------%

\begin{frame}{Comparing nested models}

 To compare fit of two nested models, you need:
  \begin{enumerate}
    \item ${\chi}^2$ of the constrained model (${\chi}^2_C$)
    \item $df_C$ of the constrained model
    \item ${\chi}^2$ of the unconstrained model(${\chi}^2_U$)
    \item $df_U$ of the unconstrained model 
  \end{enumerate}

  Then, subtract: ${\chi}^2_C$ - ${\chi}^2_u$ = ${\chi}^2_\Delta$,\\
  where ${\chi}^2_\Delta$ follows a Chi-square distribution with $df = df_C$-$df_U$. 

  \vspace{5mm}

  The function lavTestWald() does this for you!

\end{frame}

%------------------------------------------------------------------------------%

\begin{frame}[fragile]{Comparing nested models Ctd.}

  \textbf{Hypotheses} \\
  $H_0$: Unconstrained model fit = constrained model fit \\
  $H_A$: Unconstrained model fit $\neq$ constrained model fit

  \vspace{5mm}

  \textbf{High p-values:} No significant difference between the model fits: \\
  No evidence that the coefficients differ across groups. 

  \vspace{5mm}

  \textbf{Low p-values:} Significant difference between the model fits: \\
  Evidence that the coefficients differ across groups. 

\end{frame}

%------------------------------------------------------------------------------%

\begin{frame}[fragile]{Multigroup regression: Test equality of coefficients Ctd.}

<<>>=
## Test equality of regression slopes:
lavTestWald(fit1, constraints = 'b1m == b1f; b2m == b2f')
@ 

\end{frame}

%------------------------------------------------------------------------------%

\section{Measurement invariance (MI)}

%------------------------------------------------------------------------------%

\begin{frame}{Why do we care?}

  Construct validity:
  \begin{itemize}
    \item Is the model measuring the same thing in both (all) groups?
  \end{itemize}
  
  \vb

  Can we make a fair comparison between groups?
  \begin{itemize}
    \item Did the groups understand the questions in the same way? 
  \end{itemize}

  \vb

  Same latent score should result in the same observed scores.
  \begin{itemize}
    \item Equal slopes (factor loadings)
    \item Equal intercepts (item means)
  \end{itemize}

\end{frame}

%------------------------------------------------------------------------------%

\begin{frame}[allowframebreaks]{Stated Differently}

  \begin{figure}
    \includegraphics[width=\linewidth,height=\textheight,keepaspectratio]{../figures/slide105.png}
  \end{figure}

  \newpage

  \begin{figure}
    \includegraphics[height=0.8\textheight,keepaspectratio]{../figures/slide106.png}
  \end{figure}

  \newpage

  \begin{figure}
    \includegraphics[height=0.8\textheight,keepaspectratio]{../figures/slide107.png}
  \end{figure}

  \newpage

  \begin{figure}
    \includegraphics[height=0.8\textheight,keepaspectratio]{../figures/slide108.png}
  \end{figure}

  \newpage

  \begin{figure}
    \includegraphics[height=0.8\textheight,keepaspectratio]{../figures/slide109.png}
  \end{figure}

  \newpage

  \begin{figure}
    \includegraphics[height=0.8\textheight,keepaspectratio]{../figures/slide110.png}
  \end{figure}

  \newpage

  \begin{figure}
    \includegraphics[height=0.8\textheight,keepaspectratio]{../figures/slide111.png}
  \end{figure}

  \newpage

  \begin{figure}
    \includegraphics[height=0.8\textheight,keepaspectratio]{../figures/slide112.png}
  \end{figure}

  \newpage

  \begin{figure}
    \includegraphics[height=0.8\textheight,keepaspectratio]{../figures/slide113.png}
  \end{figure}

  \newpage

  \begin{figure}
    \includegraphics[height=0.8\textheight,keepaspectratio]{../figures/slide114.png}
  \end{figure}

  \newpage

  \begin{figure}
    \includegraphics[height=0.8\textheight,keepaspectratio]{../figures/slide115.png}
  \end{figure}

  \newpage

  \begin{figure}
    \includegraphics[height=0.8\textheight,keepaspectratio]{../figures/slide116.png}
  \end{figure}

\end{frame}

%------------------------------------------------------------------------------%

\begin{frame}{Confirmatory bottom-up approach}

  \begin{enumerate}
    \item Test model separately for each group (\textbf{configural invariance}).
      \begin{itemize}
        \item Must fit the data
      \end{itemize}
    \item Test equality of loadings across groups (\textbf{metric/weak invariance}).
      \begin{itemize}
        \item Must be equal
      \end{itemize}
    \item Test equality of intercepts across groups (\textbf{scalar/strong invar.}).
      \begin{itemize}
        \item Must be equal
      \end{itemize}
    \item Test equality of measurement error variances (\textbf{strict invariance}).
      \begin{itemize}
        \item Not essential, often overly restrictive
      \end{itemize}
  \end{enumerate}

\end{frame}

%------------------------------------------------------------------------------%

\begin{frame}{Testing measurement invariance (MI)}

  \begin{columns}[T] % align columns
    \begin{column}{.75\textwidth}

      \begin{enumerate}
        \item Test overall model.
        \item Test model for groups separately.
        \item Test equal factor loadings ($\lambda_1$, $\lambda_2$, $\lambda_3$,).
        \item Test equal intercepts / item means ($\nu_1$, $\nu_2$, $\nu_3$,).
        \item Test equal residual/error variances ($\epsilon_1$, $\epsilon_2$, $\epsilon_3$,).
        \item Test factor means ($\alpha$) and/or variances ($\Psi$).
      \end{enumerate}
    \end{column}%

    \hfill%
    \begin{column}{.24\textwidth}

      \includegraphics[width=\textwidth,keepaspectratio]{../figures/FactorModel.png}

    \end{column}%
  \end{columns}

  \vspace{5mm}

  Note: Steps 3, 4, and 5, that is, testing for configural invariance, metric/weak invariance, and scalar/strong invariance, respectively, are quite easily incorporated in lavaan.

\end{frame}

%------------------------------------------------------------------------------%

\section{MI in R}

%------------------------------------------------------------------------------%

\begin{frame}{Example: South African Personality Inventory Project (SAPI)}

  \begin{figure}
  \includegraphics[width = \textwidth]{../figures/SAPI.png}
  \end{figure}

\end{frame}

%------------------------------------------------------------------------------%

\begin{frame}[fragile]{SAPI Example: MI models with lavaan}

<<>>=
## Read in the data:
sapi <- read.table("../data/sapi.txt",
                   header = TRUE, 
                   na.strings = "-999") %>%
mutate(sex = factor(Gender, labels = c("male", "female"))) %>%
filter(!is.na(sex))

## Define the model syntax:
cfaMod <- '
having_fun  =~ Q77 + Q84 + Q196 
being_liked =~ Q44 + Q63 + Q98
'

## Fit the model:
@ 

\end{frame}

%------------------------------------------------------------------------------%

\begin{frame}[fragile]{SAPI Example: MI models with lavaan Ctd.}

<<>>=
## Configurally invariant model:
configFit <- cfa(cfaMod, 
                 data = sapi, 
                 std.lv = TRUE, 
                 group = "sex", 
                 missing = "FIML")

## Weakly invariant model:
weakFit <- cfa(cfaMod, 
               data = sapi, 
               std.lv = TRUE, 
               group = "sex", 
               group.equal = "loadings",
               missing = "FIML")

## Strongly invariant model:
strongFit <- cfa(cfaMod, 
                 data = sapi, 
                 std.lv = TRUE, 
                 group = "sex", 
                 group.equal = c("loadings", "intercepts"),
                 missing = "FIML")
@ 

\end{frame}

%------------------------------------------------------------------------------%

\begin{frame}[fragile]{SAPI Example: Testing MI with lavaan}

<<>>=
library(semTools)
compareFit(configFit, weakFit, strongFit) %>% summary()
@ 

\begin{itemize}
  \item Metric/Weak invariance model fits just as well as the configural invariance model ($\chi^2(4) = 1.40$, $p = .84$).
  \item Scalar/Strong invariance model also fits just as well as the metric/weak invariance model ($\chi^2(4) = 7.38$, $p = .12$).
\end{itemize}

\end{frame}

%------------------------------------------------------------------------------%

\begin{frame}{SAPI Example: MI - Model fit}

\footnotesize{
  $-$ Cheung, G. W., \& Rensvold, R. B. (2002). Evaluating goodness-of-fit indexes for testing measurement invariance. Structural Equation Modeling, 9(2), 233–255. doi:10.1207/S15328007SEM0902\_5

  %\vspace{5mm}

  $-$ Chen, F. F. (2007). Sensitivity of goodness of fit indexes to lack of measurement invariance. Structural Equation Modeling, 14(3), 464–504. doi:10.1080/10705510701301834
}
\end{frame}

%------------------------------------------------------------------------------%

\begin{frame}{Testing MI with lavaan: IF significant}

  \begin{itemize}
    \item If the test for configural invariance against weak invariance is significant, then there is a lack of metric invariance and, thus, there is no need to test for scalar and strict invariance.\\
      \vspace{5mm}
    \item If tests significant: may try to find source of bias with modification indices.
    \item Then, aim for partial MI: Continue with MI tests with source of bias freely estimated between groups.
  \end{itemize}

\end{frame}

%------------------------------------------------------------------------------%

\begin{frame}{Moderation via Multiple Group SEM}
  
  When our moderator is a categorical variable, we can use multiple group 
  CFA/SEM to test for moderation.
  \va
  \begin{itemize}
    \item Categorical moderators define groups.
      \vb
    \item Significant moderation with categorical moderators implies
      between-group differences in the focal effect.
      \vb
    \item We can directly test these hypotheses with multiple group SEM.
  \end{itemize}
  
\end{frame}

\watermarkoff %%%------------------------------------------------------------%%%

\begin{frame}[fragile]{Example}

<<>>=
## Read the data and subset to only high school and college graduates:
bfi <- readRDS("../data/bfiData2.rds") %>% 
    filter(educ %in% c("highSchool", "college"))

## Specify the (configurally invariance) measurement model:
mod0 <- '
agree =~ A1 + A2 + A3 + A4 + A5
open  =~ O1 + O2 + O3 + O4 + O5
'

## Estimate the unrestricted model:
out0 <- cfa(mod0, data = bfi, std.lv = TRUE, group = "educ")
@ 

\end{frame}

%%%--------------------------------------------------------------------------%%%

\begin{frame}[fragile, allowframebreaks]{Example}
  
<<eval = FALSE>>=
## Define the weakly invariant model:
mod1 <- measEq.syntax(configural.model = out0, 
                      group = "educ", 
                      group.equal = "loadings") %>% 
    as.character()

## Define the strongly invariant model:
mod2 <- measEq.syntax(configural.model = out0, 
                      group = "educ", 
                      group.equal = c("loadings", "intercepts")
                      ) %>% 
    as.character()

## Estimate the models:
out1 <- cfa(mod1, data = bfi, group = "educ")
out2 <- cfa(mod2, data = bfi, group = "educ")

## Test measurement invariance:
compareFit(out0, out1, out2) %>% summary()
@

\pagebreak

<<echo = FALSE>>=
options(width = 80)

## Define the weakly invariant model:
mod1 <- measEq.syntax(configural.model = out0, 
                      group = "educ", 
                      group.equal = "loadings") %>% 
    as.character()

## Define the strongly invariant model:
mod2 <- measEq.syntax(configural.model = out0, 
                      group = "educ", 
                      group.equal = c("loadings", "intercepts")
                      ) %>% 
    as.character()

## Estimate the models:
out1 <- cfa(mod1, data = bfi, group = "educ")
out2 <- cfa(mod2, data = bfi, group = "educ")

## Test measurement invariance:
compareFit(out0, out1, out2) %>% summary()
@

\end{frame}

%%%--------------------------------------------------------------------------%%%

\begin{frame}[fragile, allowframebreaks]{Example}

<<>>=
## Specify a structural model:
mod3 <- '
agree =~ A1 + A2 + A3 + A4 + A5
open  =~ O1 + O2 + O3 + O4 + O5

agree ~ open  
'

## Estimate the model with strong invariance constraints:
out3 <- sem(mod3, 
            data = bfi, 
            std.lv = TRUE, 
            group = "educ", 
            group.equal = c("loadings", "intercepts")
            )
@

\pagebreak

<<>>=
## Check the group-specific slopes:
partSummary(out3, c(8, 10, 14, 16))
@ 

\pagebreak

<<>>=
## Specify the restricted model:
mod4 <- '
agree =~ A1 + A2 + A3 + A4 + A5
open  =~ O1 + O2 + O3 + O4 + O5

agree ~ c(beta, beta) * open  
'

## Estimate the model:
out4 <- sem(mod4, 
            data = bfi, 
            std.lv = TRUE, 
            group = "educ", 
            group.equal = c("loadings", "intercepts")
            )
@ 

\pagebreak

<<>>=
## Check the slopes:
partSummary(out4, c(8, 10, 14, 16))
@ 

\pagebreak

<<>>=
## Do a chi-squared difference test for moderation:
anova(out3, out4)
@ 

\pagebreak

<<warning = FALSE>>=
## Do a similar test via OLS regression:
readRDS("../data/bfiData1.rds") %>% 
    filter(educ %in% c("highSchool", "college")) %$%
    lm(agree ~ open * educ) %>%
    partSummary(-(1:2))
@ 

\end{frame}

\watermarkon %%%-------------------------------------------------------------%%%

\begin{frame}{Probing Multiple Group Moderation}
  
  Testing moderation with multiple group SEM has several advantages.
  \va
  \begin{itemize}
    \item Remove measurement error from the estimates
      \vb
    \item Test for factorial invariance
      \vb
    \item All simple effects are directly estimated in the unrestricted model
  \end{itemize}
  
\end{frame}

\watermarkoff %%%------------------------------------------------------------%%%

\begin{frame}[fragile]{Simple Slopes \& Intercepts}
 
<<echo = FALSE>>=
## Check the simple slopes and intercepts:
partSummary(out3, c(8, 10, 11, 14, 16, 17), c(1:9, 20, 22:31, 42))
@ 

\end{frame}

%%%--------------------------------------------------------------------------%%%

\begin{frame}[fragile, allowframebreaks]{Simple Slopes Visualized}
 
We can visualize the simple slopes by plotting the factor scores.

<<>>=
library(ggplot2)

## Generate factor scores:
tmp <- predict(out3)

## Stack factor scores into a "tidy" dataset:
pData <- data.frame(do.call(rbind, tmp),
                    group = rep(names(tmp), sapply(tmp, nrow))
                    )

## Create a simple slopes plot:
ssPlot <- ggplot(pData, aes(open, agree, color = group)) + 
    geom_point(alpha = 0.1) + 
    geom_smooth(method = "lm") + 
    theme_classic()
@ 

\pagebreak

<<echo = FALSE, fig.height = 4.5>>=
print(ssPlot)
@ 

\end{frame}


\end{document}
